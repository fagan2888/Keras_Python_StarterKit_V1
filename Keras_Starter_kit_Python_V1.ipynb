{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_Starter_kit_Python_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhir-acharya/Keras_Python_StarterKit_V1/blob/master/Keras_Starter_kit_Python_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKUvS1l_Og8o",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "> # Keras_Starter_Kit_Python_draft_v1\n",
        "\n",
        "Keras is a powerful and easy-to-use deep learning library for various ML/DL frameworks like Theano and TensorFlow that provides a high-level neural networks API to develop and evaluate deep learning models.\n",
        "\n",
        "Below cheetsheet contains some Basic Keras setup/coding examples for ML/ DL problems\n",
        "\n",
        "[**Keras Cheetsheet** ](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80dfqKrBOcsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Simple Keras Example\n",
        "\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "data = np.random.random((1000,100))\n",
        "labels = np.random.randint(2,size=(1000,1))\n",
        "model = Sequential()\n",
        "model.add(Dense(32, activation='relu', input_dim=100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(data,labels,epochs=10,batch_size=32)\n",
        "predictions = model.predict(data)\n",
        "\n",
        "# Data\n",
        "\n",
        "Your data needs to be stored as NumPy arrays or as a list of NumPy arrays. \n",
        "Ideally, you split the data in training and test sets, for which you can also resort to the train_test_split module of sklearn.cross_validation.\n",
        "\n",
        "## Keras Data Sets\n",
        "\n",
        "from keras.datasets import boston_housing, mnist, cifar10, imdb\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "(x_train2,y_train2),(x_test2,y_test2) = boston_housing.load_data()\n",
        "(x_train3,y_train3),(x_test3,y_test3) = cifar10.load_data()\n",
        "(x_train4,y_train4),(x_test4,y_test4) = imdb.load_data(num_words=20000)\n",
        "num_classes = 10\n",
        "\n",
        "## Other dataset import from website\n",
        "\n",
        " from urllib.request import urlopen\n",
        " data = np.loadtxt(urlopen(\"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"),delimiter=\",\")\n",
        " X = data[:,0:8]\n",
        " y = data [:,8]\n",
        "\n",
        "# Preprocessing\n",
        "\n",
        "#Preprocess input data (examples)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
        "X_train = X_train.astype(‘float32’)\n",
        "X_test = X_test.astype(‘float32’)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "#Preprocess class labels\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "## Sequence Padding\n",
        "\n",
        " from keras.preprocessing import sequence\n",
        " x_train4 = sequence.pad_sequences(x_train4,maxlen=80)\n",
        " x_test4 = sequence.pad_sequences(x_test4,maxlen=80)\n",
        "\n",
        "## One-Hot Encoding\n",
        "\n",
        " from keras.utils import to_categorical\n",
        " Y_train = to_categorical(y_train, num_classes)\n",
        " Y_test = to_categorical(y_test, num_classes)\n",
        " Y_train3 = to_categorical(y_train3, num_classes)\n",
        " Y_test3 = to_categorical(y_test3, num_classes)\n",
        "\n",
        "## Multi-Hotencoding (to-do)\n",
        "\n",
        "## Train And Test Sets\n",
        "\n",
        " from sklearn.model_selection import train_test_split\n",
        " X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "## Standardization/Normalization\n",
        "\n",
        " from sklearn.preprocessing import StandardScaler\n",
        " scaler = StandardScaler().fit(x_train2)\n",
        " standardized_X = scaler.transform(x_train2)\n",
        " standardized_X_test = scaler.transform(x_test2)\n",
        "\n",
        "# Model Architecture\n",
        "\n",
        "## Sequential Model\n",
        "\n",
        " from keras.models import Sequential\n",
        " model = Sequential()\n",
        " model2 = Sequential()\n",
        " model3 = Sequential()\n",
        "\n",
        "## Multi-Layer Perceptron (MLP)\n",
        "### Binary Classification\n",
        "\n",
        " from keras.layers import Dense\n",
        " model.add(Dense(12, input_dim=8, kernel_initializer='uniform', activation='relu'))\n",
        " model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
        " model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "\n",
        "### Multi-Class Classification\n",
        "\n",
        " from keras.layers import Dropout\n",
        " model.add(Dense(512,activation='relu',input_shape=(784,)))\n",
        " model.add(Dropout(0.2))\n",
        " model.add(Dense(512,activation='relu'))\n",
        " model.add(Dropout(0.2))\n",
        " model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "### Regression\n",
        "\n",
        " model.add(Dense(64, activation='relu', input_dim=train_data.shape[1]))\n",
        " model.add(Dense(1))\n",
        "\n",
        "## Convolutional Neural Network (CNN)\n",
        "\n",
        " from keras.layers import Activation, Conv2D, MaxPooling2D, Flatten\n",
        " model2.add(Conv2D(32, (3,3), padding='same', input_shape=x_train.shape[1:]))\n",
        " model2.add(Activation('relu'))\n",
        " model2.add(Conv2D(32, (3,3)))\n",
        " model2.add(Activation('relu'))\n",
        " model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        " model2.add(Dropout(0.25))\n",
        " model2.add(Conv2D(64, (3,3), padding='same'))\n",
        " model2.add(Activation('relu'))\n",
        " model2.add(Conv2D(64, (3, 3)))\n",
        " model2.add(Activation('relu'))\n",
        " model2.add(MaxPooling2D(pool_size=(2,2)))\n",
        " model2.add(Dropout(0.25))\n",
        " model2.add(Flatten())\n",
        " model2.add(Dense(512))\n",
        " model2.add(Activation('relu'))\n",
        " model2.add(Dropout(0.5))\n",
        " model2.add(Dense(num_classes))\n",
        " model2.add(Activation('softmax'))\n",
        "\n",
        "## Recurrent Neural Network (RNN)\n",
        "\n",
        " from keras.klayers import Embedding,LSTM\n",
        " model3.add(Embedding(20000,128))\n",
        " model3.add(LSTM(128,dropout=0.2,recurrent_dropout=0.2))\n",
        " model3.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# Defining model architecture (generally)\n",
        " model = Sequential()\n",
        "-----\n",
        " model.add(Convolution2D(32, 3, 3, activation=’relu’, input_shape=(1,28,28)))\n",
        " model.add(Convolution2D(32, 3, 3, activation=’relu’))\n",
        " model.add(MaxPooling2D(pool_size=(2,2)))\n",
        " model.add(Dropout(0.25))\n",
        "-----\n",
        " model.add(Flatten())\n",
        " model.add(Dense(128, activation=’relu’))\n",
        " model.add(Dropout(0.5))\n",
        " model.add(Dense(10, activation=’softmax’))\n",
        "\n",
        "# Inspect Model\n",
        "\n",
        "## Model output shape\n",
        "\n",
        " model.output_shape\n",
        "\n",
        "## Model summary representation\n",
        "\n",
        " model.summary()\n",
        "\n",
        "## Model configuration\n",
        "\n",
        " model.get_config()\n",
        "\n",
        "## List all weight tensors in the model\n",
        "\n",
        " model.get_weights()\n",
        "\n",
        "# Compile Model\n",
        " model.compile(loss=’categorical_crossentropy’,\n",
        "  optimizer=’adam’,\n",
        "  metrics=[‘accuracy’])\n",
        "\n",
        "## Multi-Layer Perceptron (MLP)\n",
        "### MLP: Binary Classification\n",
        "\n",
        " model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "### MLP: Multi-Class Classification\n",
        "\n",
        " model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "### MLP: Regression\n",
        "\n",
        " model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "\n",
        "## Recurrent Neural Network (RNN)\n",
        "\n",
        " model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model Training\n",
        "\n",
        " model3.fit(x_train4, y_train4, batch_size=32, epochs=15, verbose=1, validation_data=(x_test4, y_test4))\n",
        "\n",
        "# Fit model on training data (same as above)\n",
        " model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)\n",
        "\n",
        "# Evaluate model on test data\n",
        " score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "# Evaluate Your Model's Performance\n",
        "\n",
        " score = model3.evaluate(x_test, y_test, batch_size=32)\n",
        "\n",
        "# Prediction\n",
        "\n",
        "\n",
        " model3.predict(x_test4, batch_size=32)\n",
        " model3.predict_classes(x_test4,batch_size=32)\n",
        "\n",
        "# Save/Reload Models\n",
        "\n",
        "\n",
        " from keras.models import load_model\n",
        " model3.save('model_file.h5')\n",
        " my_model = load_model('my_model.h5')\n",
        "\n",
        "# Model Fine-Tuning\n",
        "\n",
        "## Optimization Parameters\n",
        "\n",
        " from keras.optimizers import RMSprop\n",
        " opt = RMSprop(lr=0.0001, decay=1e-6)\n",
        " model2.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "## Early Stopping\n",
        "\n",
        " from keras.callbacks import EarlyStopping\n",
        " early_stopping_monitor = EarlyStopping(patience=2)\n",
        " model3.fit(x_train4,y_train4,batch_size=32,epochs=15,validation_data=(x_test4, y_test4), callbacks[early_stopping_monitor])\n",
        "\n",
        "\n",
        " #Auto-Keras (to-do)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}